{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7015be79",
   "metadata": {},
   "source": [
    "# Introduction to Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5e541",
   "metadata": {},
   "source": [
    "## **A. What are Chatbots?**\n",
    "**Chatbots** are conversational programs that automate interactions. They are artificial intelligence (AI) softwares designed to simulate conversation with human users, typically through text or voice. Chatbots are used to automate customer support, provide information, and even entertain. They interact with users by responding to their questions, giving helpful information, or carrying out tasks based on the input.\n",
    "\n",
    "- **Examples**: \n",
    "  - A chatbot on a bank's website that helps with account inquiries.\n",
    "  - A chatbot on an e-commerce site that tracks orders or provides product recommendations.\n",
    "  - Virtual assistants like **Siri** and **Alexa** are advanced chatbots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4688498",
   "metadata": {},
   "source": [
    "## **B. Difference Between Chatbots and Bots**\n",
    "\n",
    "**Chatbots** are a subset of bots. They are specifically designed for conversation, meaning they are programmed to interact using natural language processing (NLP) to simulate human conversation. \n",
    "\n",
    "**Bots**, on the other hand, are more general-purpose programs designed to automate tasks. They don’t necessarily interact with users in natural language, but they perform specific functions like web scraping, sending reminders, or managing social media posts.\n",
    "\n",
    "- **Chatbot**: Focuses on conversation (e.g., answering customer queries).\n",
    "- **Bot**: Focuses on automating repetitive tasks (e.g., posting scheduled tweets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f00a8a",
   "metadata": {},
   "source": [
    "## **C. Types of Chatbots**\n",
    "\n",
    "Chatbots are generally classified into three categories based on how they respond to user input:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75fca64",
   "metadata": {},
   "source": [
    "### 1. **Rule-Based Chatbots**:\n",
    "- **How they work**: Think of rule-based chatbots like a robot that follows a set of instructions or rules. If you say something it recognizes, it will respond with a pre-written answer. For example, if you ask \"What’s your name?\", the bot might always reply, \"I’m Botty!\". It works by looking for specific keywords or patterns in what you say and then picking the correct response from its list.\n",
    "- **Limitation**: The problem is, if you ask something it wasn’t programmed for, like \"What’s your favorite color?\", it might get confused or give a response that doesn’t make sense. It’s like only being able to talk to someone about a few topics—if you go off-script, the conversation won’t flow.\n",
    "- **Example**: Imagine a chatbot for a pizza place. If you ask, \"What are your hours?\", it will answer something like, \"We’re open from 10 AM to 10 PM.\" But if you ask, \"What’s your favorite pizza?\", it might just say, \"I don’t understand.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f2562e",
   "metadata": {},
   "source": [
    "### 2. **Retrieval-Based Chatbots**:\n",
    "- **How they work**: These chatbots are a bit smarter than rule-based ones. Instead of giving a fixed reply, they search through a bunch of pre-written responses and try to find the best one based on what you said. It’s like going through a library to find the book that most closely answers your question. \n",
    "- **Techniques Used**:\n",
    "  - **Jaccard Similarity**: Imagine you ask a question like, \"What’s the weather today?\" The bot checks which of its stored answers have the most words in common with your question. The more words they share, the more likely it is to pick that answer.\n",
    "  - **Cosine Similarity**: This is like comparing two texts using math. It turns your words into numbers and checks how similar they are. If the numbers line up, the bot figures that the answer might be a good fit.\n",
    "  - **Machine learning models like `Naive Bayes`**: This is where the bot starts to guess what you’re talking about by learning from past examples. If it’s been trained to answer questions about sports, it’ll know that when you ask about “football”, it should probably give a sports-related response.\n",
    "- **Example**: Think of a customer service chatbot. If you type \"I need help with my order\", the bot searches for similar phrases it knows, like \"I have a problem with my order\", and then provides the best response, like \"Please provide your order number so I can help.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef907d94",
   "metadata": {},
   "source": [
    "#### Let's break down Retrieval-Based methods a bit more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c11a7",
   "metadata": {},
   "source": [
    "##### **Jaccard Similarity**:\n",
    "\n",
    "- **What it is**: Jaccard similarity compares two sets of words and checks how similar they are by looking at how many words they share. It’s like checking how much two circles overlap when placed on top of each other. The more overlap, the more similar they are.\n",
    "  \n",
    "- **Formula**:  \n",
    "  $\n",
    "  \\text{Jaccard Similarity} = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "  $\n",
    "  Where:\n",
    "  - $A \\cap B$ is the number of words that both sets (A and B) have in common.\n",
    "  - $A \\cup B$ is the total number of unique words in both sets combined.\n",
    "\n",
    "- **Example**:\n",
    "  If you have two sentences:\n",
    "  - Sentence 1: \"I love cats\"\n",
    "  - Sentence 2: \"I love dogs\"\n",
    "\n",
    "  The Jaccard similarity would be calculated by comparing the words:\n",
    "  - Common words (intersection): \"I\", \"love\" (2 words)\n",
    "  - Total unique words (union): \"I\", \"love\", \"cats\", \"dogs\" (4 words)\n",
    "\n",
    "  Jaccard Similarity = $(\\frac{2}{4} = 0.5)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d694788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Code example\n",
    "\n",
    "# Function to compute the Jaccard Similarity between two sets\n",
    "def jaccard_similarity(set1, set2):\n",
    "    # Calculate the number of elements in the intersection of the two sets\n",
    "    intersection = len(set(set1).intersection(set(set2)))\n",
    "    \n",
    "    # Calculate the number of elements in the union of the two sets\n",
    "    union = len(set(set1).union(set(set2)))\n",
    "    \n",
    "    # Return the Jaccard Similarity (ratio of intersection over union)\n",
    "    return intersection / union\n",
    "\n",
    "# Example: Calculate Jaccard Similarity between two sentences\n",
    "# The sentences are split into words (tokens), which are compared\n",
    "sentence1 = \"I love cats\".split()  # Split sentence1 into ['I', 'love', 'cats']\n",
    "sentence2 = \"I love dogs\".split()  # Split sentence2 into ['I', 'love', 'dogs']\n",
    "\n",
    "# Print the Jaccard Similarity between the two sentences (based on word overlap)\n",
    "print(jaccard_similarity(sentence1, sentence2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22357b",
   "metadata": {},
   "source": [
    "##### Cosine Similarity:\n",
    "\n",
    "- **What it is**: Cosine similarity compares two sentences (or documents) by turning them into vectors (a way to represent words as numbers) and measuring the angle between them. If the angle is small, the sentences are more similar. Think of it like checking how close two arrows point in the same direction.\n",
    "  \n",
    "- **Formula**:\n",
    "  $\n",
    "  \\text{Cosine Similarity} = \\frac{A \\cdot B}{||A|| \\times ||B||}\n",
    "  $\n",
    "  Where:\n",
    "  - $A \\cdot B$ is the dot product of the two vectors (basically multiplying each pair of numbers from both vectors and adding them up).\n",
    "  - $||A||$ and $||B||$ are the magnitudes (or lengths) of the vectors.\n",
    "\n",
    "- **Example**:\n",
    "  If we use a simple example with word counts, where each word represents a dimension:\n",
    "  - Sentence 1: \"I love cats\" → [1, 1, 1, 0] (This is a vector with: 1 \"I\", 1 \"love\", 1 \"cats\", 0 \"dogs\") \n",
    "  - Sentence 2: \"I love dogs\" → [1, 1, 0, 1] (1 \"I\", 1 \"love\", 0 \"cats\", 1 \"dogs\")\n",
    "\n",
    "  Cosine similarity measures how closely these two lists of numbers (vectors) align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14457f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.5]\n",
      " [0.5 1. ]]\n"
     ]
    }
   ],
   "source": [
    "# Code Example\n",
    "\n",
    "# Import CountVectorizer to convert text data into vectors (token counts)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import cosine_similarity to compute similarity between vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example sentences to compare\n",
    "sentences = [\"I love cats\", \"I love dogs\"]\n",
    "\n",
    "# Convert sentences to vectors based on word counts (Bag-of-Words model)\n",
    "vectorizer = CountVectorizer()  # Initialize CountVectorizer\n",
    "vector_matrix = vectorizer.fit_transform(sentences).toarray()  \n",
    "# fit_transform: Tokenizes the sentences and counts the frequency of each word, \n",
    "# resulting in a vector representation of each sentence.\n",
    "# toarray(): Converts the resulting sparse matrix into a dense numpy array.\n",
    "\n",
    "# Compute Cosine Similarity between the vectors of the sentences\n",
    "cosine_sim = cosine_similarity(vector_matrix)\n",
    "# cosine_similarity calculates the cosine of the angle between the vectors,\n",
    "# giving a similarity measure between 0 (no similarity) and 1 (identical).\n",
    "\n",
    "# Print the Cosine Similarity matrix\n",
    "print(cosine_sim) # Output: [[1. 0.5], [0.5 1.]]\n",
    "\n",
    "# In this case, the cosine similarity between \"I love cats\" and \"I love dogs\" is 0.5, meaning they’re somewhat similar\n",
    "# (since they share \"I\" and \"love\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af493242",
   "metadata": {},
   "source": [
    "#### Summary of Differences:\n",
    "- **Jaccard Similarity** is simpler and great for comparing the overall similarity between two sets of words based on how much they overlap (shared words). \n",
    "- **Cosine Similarity** is more useful when the sentences are longer and you want to compare how similar they are based on the direction of the vectors (word counts)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307231d0",
   "metadata": {},
   "source": [
    "##### Naive Bayes for Classification:\n",
    "\n",
    "Naive Bayes is a type of algorithm that helps computers make decisions or **classify** things. When you use it in a chatbot, it can help figure out what the user is asking about (the user's intent), then pick the right answer from a set of possible replies.\n",
    "\n",
    "##### **How It Works**:\n",
    "\n",
    "1. **Training the Bot**:\n",
    "   You first need to give the chatbot some **training data**. This is like teaching it by showing examples of questions and their categories, or what they're asking for. For example:\n",
    "   - \"What time is it?\" would be categorized as a **time question**.\n",
    "   - \"Tell me a joke\" would be categorized as a **joke request**.\n",
    "\n",
    "   Each example teaches the chatbot what types of questions belong to each category.\n",
    "\n",
    "2. **Classifying the User's Question**:\n",
    "   Once the chatbot is trained, it can take a new question from a user and use the **Naive Bayes** algorithm to guess what category that question falls into. For example, if someone asks, \"What's the time?\", the chatbot might classify it as a **time request**.\n",
    "\n",
    "3. **Finding the Answer**:\n",
    "   After it figures out what the question is about, the chatbot then **retrieves** (picks) the right answer from a list of possible responses. For example:\n",
    "   - If the chatbot classifies the question as a **time request**, it will respond with something like, \"It's 3 PM.\"\n",
    "\n",
    "##### **In Simple Terms**:\n",
    "Naive Bayes helps the chatbot **understand** what type of question you're asking. Even though it uses the Naive Bayes algorithm to figure out the question type, the chatbot still pulls the answer from a **pre-written list** of answers—it doesn’t make up answers on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b087720",
   "metadata": {},
   "source": [
    "### 3. **Generative Chatbots**:\n",
    "- **How they work**: These are the most advanced chatbots. Instead of pulling from a list of pre-written answers, they create their own responses based on what you said. It’s like having a conversation with someone who thinks on the spot and makes up their answers. \n",
    "    - They use advanced machine learning models, typically deep learning models like RNNs, LSTMs, or transformers (like GPT), to generate new sentences based on the input.\n",
    "\n",
    "- **Limitation**: Generative chatbots need a lot of training to get good at answering questions, and sometimes, they say things that don’t make much sense because they’re making everything up as they go along. They can get confused if they haven’t been trained well.\n",
    "\n",
    "- **Example**: ChatGPT is a generative chatbot. When you ask it something like, \"What’s your favorite book?\", it doesn’t pick from a list. Instead, it thinks about the question and creates an answer based on patterns it learned from reading lots of text. So, you might get something like, \"I don't have favorites, but I’ve read a lot about Harry Potter!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc40d9",
   "metadata": {},
   "source": [
    "### An example illustrating rule-based, retrieval-based, and generative chatbots using a simple customer service scenario related to order tracking\n",
    "\n",
    "\n",
    "##### Scenario \n",
    "The user asks: **\"Where is my order?\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c1b26",
   "metadata": {},
   "source": [
    "**1. Rule-Based Chatbot Example:**\n",
    "In a rule-based chatbot, predefined keywords like \"order\" and \"track\" are used to trigger specific responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fc4c9d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your order number to track your order.\n"
     ]
    }
   ],
   "source": [
    "# Define a function for a simple rule-based chatbot\n",
    "def rule_based_chatbot(user_input):\n",
    "    # Check if the user input contains the words \"track\" or \"order\"\n",
    "    if \"track\" in user_input.lower() or \"order\" in user_input.lower():\n",
    "        # Respond with a prompt to provide an order number\n",
    "        return \"Please provide your order number to track your order.\"\n",
    "    \n",
    "    # Check if the user input contains the word \"refund\"\n",
    "    elif \"refund\" in user_input.lower():\n",
    "        # Respond with information about the refund policy\n",
    "        return \"For a refund, please visit our refund policy page.\"\n",
    "    \n",
    "    # If the input doesn't match any of the predefined rules\n",
    "    else:\n",
    "        # Respond with a message indicating the chatbot doesn't understand the query\n",
    "        return \"I'm sorry, I didn't understand that. Can you try again?\"\n",
    "\n",
    "# Example user input\n",
    "user_query = \"Where is my order?\"\n",
    "\n",
    "# Call the rule-based chatbot function with the user's query\n",
    "print(rule_based_chatbot(user_query))\n",
    "\n",
    "# Output: \"Please provide your order number to track your order.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e7fdd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For a refund, please visit our refund policy page.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_based_chatbot(\"I need a refund\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb3073",
   "metadata": {},
   "source": [
    "**How it works**: It looks for the keywords **\"track\"** or **\"order\"** and returns a fixed response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198dbc57",
   "metadata": {},
   "source": [
    "#### **2. Retrieval-Based Chatbot Example (Jaccard Similarity):**\n",
    "In a retrieval-based chatbot, the bot looks for similar sentences in a predefined set of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9e56e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your order number to track your order.\n"
     ]
    }
   ],
   "source": [
    "# Sorry, but you may have to skip to section E to install and download the necessary nltk stuff first. \n",
    "# Thanks for your understanding\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# A predefined set of possible responses for the chatbot\n",
    "responses = [\n",
    "    \"Please provide your order number to track your order.\",\n",
    "    \"For a refund, please visit our refund policy page.\",\n",
    "    \"Our customer service is available 24/7.\"\n",
    "]\n",
    "\n",
    "# Load a set of English stopwords (common words that may be removed in text preprocessing)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocess function to clean and prepare text data\n",
    "def preprocess(text):\n",
    "    # Tokenize the input text into individual words and convert them to lowercase\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords (e.g., 'the', 'is') and punctuation\n",
    "    words = [word for word in words if word not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    # Return the cleaned list of words\n",
    "    return words\n",
    "\n",
    "# Function to calculate Jaccard similarity between two sentences\n",
    "def jaccard_similarity(query, sentence):\n",
    "    # Preprocess the query and the sentence\n",
    "    query_set = set(preprocess(query))\n",
    "    sentence_set = set(preprocess(sentence))\n",
    "    \n",
    "    # Calculate the intersection and union of the sets and return the Jaccard similarity score\n",
    "    return len(query_set.intersection(sentence_set)) / len(query_set.union(sentence_set))\n",
    "\n",
    "# Function to find the most relevant response based on user input\n",
    "def retrieval_based_chatbot(user_input):\n",
    "    best_response = \"\"  # Placeholder for the best matching response\n",
    "    highest_similarity = 0  # Keep track of the highest Jaccard similarity score\n",
    "    \n",
    "    # Loop through each predefined response and calculate the Jaccard similarity with the user input\n",
    "    for response in responses:\n",
    "        similarity = jaccard_similarity(user_input, response)\n",
    "        \n",
    "        # Update the best response if the current response has a higher similarity score\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            best_response = response\n",
    "    \n",
    "    # Return the best response if found, otherwise return a fallback message\n",
    "    return best_response if best_response else \"I'm sorry, I couldn't find a relevant response.\"\n",
    "\n",
    "# Example user input\n",
    "user_query = \"Where is my order?\"\n",
    "\n",
    "# Call the chatbot function with the user's query and print the response\n",
    "print(retrieval_based_chatbot(user_query))\n",
    "\n",
    "# Output: \"Please provide your order number to track your order.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d215603",
   "metadata": {},
   "source": [
    "**How it works**: It compares the user's query with predefined responses and returns the most similar one using **Jaccard similarity**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd175ec1",
   "metadata": {},
   "source": [
    "#### **3. Generative Chatbot**\n",
    "In a generative chatbot, the response is generated dynamically using a machine learning model (like GPT). In a real scenario, this would involve training a deep learning model.\n",
    "\n",
    "Example response to a scenario where the user asks: **\"Where is my order?\"**:\n",
    "\n",
    "```\n",
    "\"To track your order, please provide your order number or check the tracking link sent to your email.\"\n",
    "```\n",
    "- **How it works**: The generative chatbot creates a new response based on the user input, generating an original sentence that wasn't pre-programmed or retrieved from a predefined list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb94c4a",
   "metadata": {},
   "source": [
    "## **D. Common Terms in Natural Language Processing (NLP)**\n",
    "\n",
    "### 1. **Natural Language Processing (NLP)**\n",
    "NLP is a way for computers to understand, interpret, and respond to human language. Think about how you talk to your friends through texting, and imagine if a computer could understand and respond to those texts. With NLP, computers can read, listen, and even reply like humans! It’s used in many things, like virtual assistants (Siri, Alexa), chatbots, and even spell checkers.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Tokenization**\n",
    "Tokenization is like breaking down a sentence into smaller pieces that a computer can understand. Think of it as cutting a big cake (the sentence) into small slices (the words). Each of these slices is called a token, and it can be a word or even a punctuation mark. For example, in the sentence \"I love pizza!\", the tokens would be \"I\", \"love\", \"pizza\", and \"!\".\n",
    "- **Why is it important?** Tokenization helps the computer to focus on individual words or parts of a sentence to figure out what it means.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Lemmatization**\n",
    "Lemmatization is when the computer changes words to their simplest form, called the **lemma**. For example, the word \"running\" changes to \"run\" or \"better\" changes to \"good\". This helps the computer group similar words together and understand the overall meaning of a sentence.\n",
    "- **Why is it important?** Lemmatization helps computers understand the meaning of words even when they’re written in different forms (like \"ran\" and \"running\").\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Stemming**\n",
    "Stemming is when the computer cuts off the ends of words to get the base form, or **stem**. For example, \"playing\", \"played\", and \"plays\" all become \"play\". This is different from lemmatization because it’s more about quickly chopping off word endings, even if it doesn’t always create a real word.\n",
    "- **Why is it important?** Stemming helps computers group words with similar meanings together by chopping off extra endings.\n",
    "\n",
    "##### Stemming vs. Lemmatization\n",
    "- Both **stemming** and **lemmatization** help to find the basic form of a word (root word), but they do it differently.\n",
    "- **Stemming** is like cutting off the end of a word to get the root. For example, \"running\" becomes \"run\" by removing the \"-ing\", but sometimes it cuts too much, making words that don’t look right, like \"studies\" becoming \"studi.\"\n",
    "- **Lemmatization** is smarter. It looks at the whole sentence to understand the word's meaning before changing it. So, if you have \"better,\" lemmatization knows it should turn into \"good\" because that’s the correct form.\n",
    "- **Lemmatization** is more accurate, but it takes longer because it has to think more about the words. Still, it’s better at keeping the meaning of the words correct in different sentences.\n",
    "\n",
    "\n",
    "### 5. **Stopwords**\n",
    "Stopwords are very common words, like \"the\", \"is\", \"and\", \"in\", that computers often ignore when analyzing a sentence. These words don’t add much meaning to the sentence and are usually just \"fillers.\"\n",
    "- **Why is it important?** By skipping these stopwords, the computer can focus on the important words in a sentence to understand what you’re really saying.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Corpora**\n",
    "A **corpus** (plural: corpora) is a large collection of written or spoken texts that computers use to learn and analyze language. It’s like giving the computer lots of books to read and study from. This is where NLP models get their training—by reading through corpora to understand how humans write or speak.\n",
    "- **Why is it important?** Corpora help computers get better at understanding language by giving them real examples of how words and sentences are used.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Bag of Words (BoW)**\n",
    "Bag of Words is a simple way for computers to represent text. It works by counting how many times each word appears in a text, without caring about the order of the words. Imagine you have a bag and throw all the words from a sentence into it; the computer only knows how many of each word you have, not the sequence.\n",
    "- **Why is it important?** BoW helps computers recognize which words are important by counting how often they show up, even though it doesn’t consider the sentence structure.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **TF-IDF (Term Frequency-Inverse Document Frequency)**\n",
    "TF-IDF is a more advanced version of Bag of Words. It doesn’t just count how often a word appears in a text (like BoW); it also checks how rare or important that word is across many documents. For example, common words like \"the\" will be ignored, but rare words like \"pizza\" in a group of recipes might be more important.\n",
    "- **Why is it important?** TF-IDF helps computers figure out which words are important in a group of texts by focusing on less common, more meaningful words.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Bot Frameworks (e.g., Rasa, Microsoft Bot Framework)**\n",
    "Bot frameworks are tools that help people build chatbots. It’s like using a set of Lego blocks to quickly build your own chatbot without starting from scratch. These frameworks provide all the basic tools to create, train, and deploy chatbots that can understand and respond to people’s messages.\n",
    "- **Why is it important?** Bot frameworks make it easier for people to create chatbots that can talk with users, answer questions, and perform tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### 10. **Transformers**\n",
    "Transformers are a special kind of model in NLP that help computers understand language better. They can look at a sentence as a whole instead of just one word at a time. Famous transformer models include **BERT** (used for understanding text) and **GPT** (used for generating text). Transformers have made it possible for computers to have deeper conversations and understand complex language.\n",
    "- **Why is it important?** Transformers help computers process entire sentences, making them better at answering questions, generating stories, and even holding conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a15cc",
   "metadata": {},
   "source": [
    "## **E. Possible Workflow for Building a Simple Chatbot using NLTK (Natural Language Toolkit)**\n",
    "\n",
    "Here’s a simplified workflow for building a basic retrieval-based chatbot using NLTK (a popular Python library for text processing):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a160e9",
   "metadata": {},
   "source": [
    "#### **Step 1: Install NLTK and Download Resources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NLTK and download necessary resources such as tokenizers and stopwords.\n",
    "#!pip install nltk  # Uncomment to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0456b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First time only\n",
    "nltk.download('punkt')  # Sentence and word tokenizer\n",
    "nltk.download('stopwords')  # Common words to exclude (e.g., 'the', 'is')\n",
    "nltk.download('wordnet')  # Lexical database for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0fdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f1b351",
   "metadata": {},
   "source": [
    "#### **Step 2: Load the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba4bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you want to create a chatbot based on the text of a book (e.g., \"Alice in Wonderland\").\n",
    "\n",
    "# Load text file\n",
    "with open('alice_in_wonderland.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abfb11c",
   "metadata": {},
   "source": [
    "#### **Step 3: Preprocess the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "008ffe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing involves tokenizing, removing stopwords, and lemmatizing (reducing words to their base form).\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess each sentence\n",
    "def preprocess(sentence):\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# Tokenize text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "corpus = [preprocess(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd150c6",
   "metadata": {},
   "source": [
    "#### **Step 4: Implement Jaccard Similarity for Response Matching**\n",
    "Now, we implement the **Jaccard Similarity** to find the most relevant response to a user’s query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b893d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(query, sentence):\n",
    "    query_set = set(preprocess(query))\n",
    "    sentence_set = set(sentence)\n",
    "    return len(query_set.intersection(sentence_set)) / len(query_set.union(sentence_set))\n",
    "\n",
    "def get_response(query):\n",
    "    max_similarity = 0\n",
    "    best_response = \"\"\n",
    "    for i, sentence in enumerate(corpus):\n",
    "        similarity = jaccard_similarity(query, sentence)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            #best_response = \" \".join(sentence)\n",
    "            best_response = sentences[i] # Use the original sentence with stopwords included\n",
    "    return best_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdc1dc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He had been looking at Alice for some time with great curiosity, and this was his first speech.\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "user_query = \"Who does Alice meet first in Wonderland?\"\n",
    "response = get_response(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89606e6f",
   "metadata": {},
   "source": [
    "#### **Step 5: Testing the Chatbot**\n",
    "You can now interact with your chatbot by entering different queries.\n",
    "- Sample questions:\n",
    "    1. Who does Alice meet first in Wonderland?\n",
    "    2. What is the Cheshire Cat's famous line?\n",
    "    3. How does Alice enter Wonderland?\n",
    "    4. What is the Queen of Hearts known for?\n",
    "    5. Why did Alice follow the White Rabbit?\n",
    "    6. What was Alice's reaction to the Mad Hatter's tea party?\n",
    "    7. What advice does the Caterpillar give Alice?\n",
    "    8. What is the significance of the bottle labeled 'Drink Me'?\n",
    "    9. How does the story of Alice in Wonderland end?\n",
    "    10. What game does the Queen of Hearts play with Alice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b469d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in 'quit' to quit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What advice does the Caterpillar give Alice?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Poor Alice!\n",
      "Type in 'quit' to quit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is the significance of the bottle labeled 'Drink Me'?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The poor little Lizard, Bill, was in the middle, being held up by two guinea-pigs, who were giving it something out of a bottle.\n",
      "Type in 'quit' to quit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\"Type in 'quit' to quit\")\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == \"quit\":\n",
    "        break\n",
    "    response = get_response(user_input)\n",
    "    print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6997dc8",
   "metadata": {},
   "source": [
    "## F. Build a Chatbot in Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c858f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the file chatbot_wonderland.py in write mode\n",
    "with open(\"chatbot_wonderland.py\", \"w\") as file:\n",
    "    # Writing the Streamlit code into the file\n",
    "    file.write('''\n",
    "    \n",
    "##### Let's build a beginner-friendly chatbot in Streamlit #####\n",
    "# This project will build a chatbot that reads a text file, processes it, and returns relevant answers based on user input.\n",
    "\n",
    "# Importing necessary libraries\n",
    "\n",
    "# nltk (Natural Language Toolkit) library for various text processing tasks\n",
    "import nltk\n",
    "import streamlit as st  # Streamlit is used for building interactive web applications\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize  # Tokenizers for splitting text into words and sentences\n",
    "from nltk.corpus import stopwords  # List of common words (stopwords) that are usually removed from text (like \"is\", \"the\", \"and\")\n",
    "from nltk.stem import WordNetLemmatizer  # Lemmatizer to reduce words to their base form (e.g., 'running' -> 'run')\n",
    "import string  # Python's built-in library for handling strings and punctuation\n",
    "\n",
    "# Uncomment to download necessary NLTK resources if not downloaded already\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Load stopwords and initialize lemmatizer\n",
    "stop_words = set(stopwords.words('english'))  # Load a set of common English stopwords to filter out later\n",
    "lemmatizer = WordNetLemmatizer()  # Initialize a lemmatizer to reduce words to their base form\n",
    "\n",
    "# Define a function to preprocess text (tokenizing, removing stopwords and punctuation, lemmatizing)\n",
    "def preprocess(sentence):\n",
    "    # Tokenize the sentence into words and convert to lowercase\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    \n",
    "    # Remove stopwords and punctuation from the list of words\n",
    "    words = [word for word in words if word not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    # Lemmatize each word to convert it to its base form (e.g., 'running' -> 'run')\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Return the list of processed words\n",
    "    return words\n",
    "\n",
    "# Load the text file (Alice in Wonderland)\n",
    "def load_text():\n",
    "    try:\n",
    "        # Provide the path to the text file\n",
    "        file_path = r'C:\\\\Users\\\\pc\\\\Desktop\\\\B-older\\\\Data and Stuff\\\\GMC\\\\ML GMC\\\\alice_in_wonderland.txt'\n",
    "        \n",
    "        # Open the file, read its content, and replace newline characters with spaces\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read().replace('\\\\n', ' ')\n",
    "    \n",
    "    # Handle case where the file is not found and display an error message in Streamlit\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Text file not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Tokenize the text into sentences and preprocess them\n",
    "def prepare_corpus(text):\n",
    "    # Tokenize the text into individual sentences using sent_tokenize\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Preprocess each sentence (tokenizing, removing stopwords/punctuation, and lemmatizing)\n",
    "    return [preprocess(sentence) for sentence in sentences]\n",
    "\n",
    "# Calculate Jaccard similarity between two sets\n",
    "def jaccard_similarity(query, sentence):\n",
    "    # Convert both the query and sentence to sets (unique words)\n",
    "    query_set = set(query)\n",
    "    sentence_set = set(sentence)\n",
    "    \n",
    "    # If the union of both sets is zero, return 0 to avoid division by zero\n",
    "    if len(query_set.union(sentence_set)) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Calculate the Jaccard similarity as the size of intersection divided by the size of union\n",
    "    return len(query_set.intersection(sentence_set)) / len(query_set.union(sentence_set))\n",
    "\n",
    "# Find the most relevant sentence using Jaccard similarity\n",
    "def get_most_relevant_sentence(query, corpus, original_sentences):\n",
    "    # Preprocess the user query (tokenization, stopword removal, etc.)\n",
    "    query = preprocess(query)\n",
    "    \n",
    "    # Initialize variables to store the maximum similarity and best matching sentence\n",
    "    max_similarity = 0\n",
    "    best_sentence = \"I couldn't find a relevant answer.\"  # Default response if no match is found\n",
    "    \n",
    "    # Iterate over the corpus of preprocessed sentences to find the best match\n",
    "    for i, sentence in enumerate(corpus):\n",
    "        # Calculate the Jaccard similarity between the user query and the current sentence\n",
    "        similarity = jaccard_similarity(query, sentence)\n",
    "        \n",
    "        # If the similarity score is higher than the current maximum, update the best sentence\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            best_sentence = original_sentences[i]  # Retrieve the original sentence (before preprocessing)\n",
    "    \n",
    "    # Return the most relevant sentence (or the default response if no match is found)\n",
    "    return best_sentence\n",
    "\n",
    "# Main function to create the chatbot interface in Streamlit\n",
    "def main():\n",
    "    # Title for the app\n",
    "    st.title(\"Wonderland's Novice Chatbot\")\n",
    "    \n",
    "    # A brief description of the chatbot's purpose\n",
    "    st.write(\"Hello! Ask me anything related to Alice in Wonderland!\")\n",
    "    \n",
    "    # Add a dropdown (expander) for suggested questions\n",
    "    with st.expander(\"Click me for suggestions\"):\n",
    "        st.write(\"\"\"\n",
    "        1. Who does Alice meet first in Wonderland?\n",
    "        2. What is the Cheshire Cat's famous line?\n",
    "        3. How does Alice enter Wonderland?\n",
    "        4. What is the Queen of Hearts known for?\n",
    "        5. Why did Alice follow the White Rabbit?\n",
    "        6. What was Alice's reaction to the Mad Hatter's tea party?\n",
    "        7. What advice does the Caterpillar give Alice?\n",
    "        8. What is the significance of the bottle labeled 'Drink Me'?\n",
    "        9. How does the story of Alice in Wonderland end?\n",
    "        10. What game does the Queen of Hearts play with Alice?\n",
    "        \"\"\")\n",
    "    # Load and prepare text corpus\n",
    "    text = load_text()  # Load the text from the file (Alice in Wonderland)\n",
    "    if text:\n",
    "        # Preprocess the text to create a corpus of tokenized sentences\n",
    "        corpus = prepare_corpus(text)  # Prepares the text into a list of preprocessed sentences\n",
    "        original_sentences = sent_tokenize(text)  # Tokenizes the original text into sentences for later reference\n",
    "\n",
    "        # Get user input from the Streamlit interface\n",
    "        user_input = st.text_input(\"Enter your question:\")  # Input field for the user's question\n",
    "\n",
    "        # If the user clicks the submit button\n",
    "        if st.button(\"Submit\"):\n",
    "            if user_input:\n",
    "                # Get the most relevant sentence from the corpus based on the user's input\n",
    "                response = get_most_relevant_sentence(user_input, corpus, original_sentences)\n",
    "                st.write(f\"Chatbot: {response}\")  # Display the chatbot's response\n",
    "            else:\n",
    "                st.write(\"Please enter a question.\")  # Prompt user to enter a question if the input is empty\n",
    "\n",
    "# Run the Streamlit app\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Call the main function to run the Streamlit app\n",
    "    ''')\n",
    "\n",
    "print(\"chatbot_wonderland.py creation executed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee79d9c",
   "metadata": {},
   "source": [
    "### **Steps to Run This Chatbot in Streamlit**\n",
    "\n",
    "1. **Install the required libraries**:\n",
    "   Open your terminal or command prompt and run:\n",
    "   ```bash\n",
    "   pip install streamlit nltk\n",
    "   ```\n",
    "\n",
    "2. **Place the text file**:\n",
    "   Download the text of **Alice in Wonderland** (or any other text) and save it as `alice_in_wonderland.txt` in the same directory as the Python file.\n",
    "\n",
    "3. **Run the Streamlit app**:\n",
    "   In the terminal, navigate to the directory where the script is saved and run the following command:\n",
    "   ```bash\n",
    "   streamlit run your_script_name.py\n",
    "   ```\n",
    "   This will open a new window in your browser where you can interact with the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7896cfd-a632-4e73-9f01-988002ae74ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b2ca6f2-54d6-4522-bead-58c8601dcf30",
   "metadata": {},
   "source": [
    "---\n",
    "_**Your Dataness**_,  \n",
    "**`Obinna Oliseneku`** (_**Hybraid**_)  \n",
    "**[LinkedIn](https://www.linkedin.com/in/obinnao/)** | **[GitHub](https://github.com/hybraid6)**  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
