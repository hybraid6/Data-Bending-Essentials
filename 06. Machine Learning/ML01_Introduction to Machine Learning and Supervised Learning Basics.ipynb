{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259b77e6",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning and Supervised Learning Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a402fd9",
   "metadata": {},
   "source": [
    "- Machine Learning (ML) is a field of artificial intelligence (AI) that uses statistical techniques to give computer systems the ability to **learn** from data, without being explicitly programmed.\n",
    "\n",
    "\n",
    "- Machine learning involves training algorithms to recognize patterns in data and make predictions or decisions based on that data.\n",
    "- It is used in a variety of applications, from recommendation systems to image recognition and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8fa1f3",
   "metadata": {},
   "source": [
    "### Machine Learning Types\n",
    "\n",
    "- There are three main types of machine learning:\n",
    "1. Supervised Learning: The algorithm learns from labeled training data, and makes predictions based on that data. Examples include classification and regression.\n",
    "\n",
    "2. Unsupervised Learning: The algorithm learns from unlabeled data, finding hidden patterns or intrinsic structures. Examples include clustering and association.\n",
    "\n",
    "3. Reinforcement Learning: The algorithm learns by interacting with an environment, receiving rewards or penalties for actions. Examples include game playing and robotics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcbb997",
   "metadata": {},
   "source": [
    "### Common Machine Learning Algorithms\n",
    "- Linear Regression: Used for predicting numerical outcomes (e.g., house prices).\n",
    "- Logistic Regression: Used for classification problems (e.g., predicting whether an email is spam or not).\n",
    "- Decision Trees: Models that split data into branches to make predictions based on different decision rules.\n",
    "- K-Nearest Neighbors (KNN): A simple algorithm that classifies new cases based on the majority vote of its k-nearest neighbors.\n",
    "- Support Vector Machines (SVM): Creates a decision boundary that best separates classes of data.\n",
    "- Neural Networks: Algorithms inspired by the human brain, particularly useful for tasks like image recognition and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d4bf0",
   "metadata": {},
   "source": [
    "### Workflow in Machine Learning\n",
    "- Data Collection: Gather data from various sources (e.g., CSV files, databases, APIs).\n",
    "- Data Preprocessing: Clean, normalize, and transform the data to make it usable for the model.\n",
    "- Feature Selection: Choose the most relevant features from the dataset that will have the most impact on the model's predictions.\n",
    "- Model Selection: Choose an appropriate algorithm based on the problem (e.g., linear regression, decision trees).\n",
    "- Training: Fit the model to the data by feeding it the training dataset.\n",
    "- Evaluation: Assess the model using a testing dataset and performance metrics.\n",
    "- Deployment: Once the model is performing well, it can be deployed to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd295d",
   "metadata": {},
   "source": [
    "### Machine Learning Library\n",
    "\n",
    "Popular ML libraries in Python include:\n",
    "- scikit-learn: A library for classical machine learning algorithms.\n",
    "- TensorFlow: An open-source library for deep learning developed by Google.\n",
    "- Keras: A high-level neural networks API, running on top of TensorFlow.\n",
    "- PyTorch: An open-source deep learning library developed by Facebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dfd584",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "\n",
    "- In supervised learning, you train a model using labeled data. Each input data point is matched with its correct output. The model learns from these pairs to figure out how to predict outputs for new data it hasn't seen before.\n",
    "\n",
    "- Comparison with Unsupervised Learning:\n",
    "\n",
    "    - In supervised learning, the model is trained on labeled data, whereas in unsupervised learning, the model is trained on unlabeled data and must find patterns and relationships in the data without guidance.\n",
    "\n",
    "\n",
    "**Types of Supervised Learning Problems**\n",
    "- Classification: Predicting a categorical label (e.g., spam detection, image classification).\n",
    "- Regression: Predicting a continuous value (e.g., house price prediction, temperature forecasting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b92b7",
   "metadata": {},
   "source": [
    "## Example: Predicting House Prices (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To silence warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5f22d",
   "metadata": {},
   "source": [
    "### Step 1: Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For data manipulation using DataFrames\n",
    "\n",
    "# Import functions from scikit-learn for model building and evaluation\n",
    "from sklearn.model_selection import train_test_split  # To split the dataset into training and testing sets\n",
    "from sklearn.linear_model import LinearRegression  # To create and train a linear regression model\n",
    "from sklearn.metrics import mean_squared_error  # To evaluate the model using Mean Squared Error (MSE)\n",
    "from sklearn.metrics import r2_score  # To evaluate the model using R-squared (RÂ²)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9cf10",
   "metadata": {},
   "source": [
    "### Step 2: Generate a simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42) \n",
    "# By setting the seed with np.random.seed(42), you ensure that anyone running the code will get the same random numbers, \n",
    "# making your results reproducible. \n",
    "# The number 42 is often used as a default seed in examples. However, you can set the seed to any integer value.  \n",
    "# The reason 42 is commonly chosen is not technical, but rather cultural. \n",
    "# It's a reference to the book \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams, \n",
    "# where 42 is humorously declared as the \"Answer to the Ultimate Question of Life, the Universe, and Everything.\"\n",
    "\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 100\n",
    "\n",
    "\n",
    "# Generate synthetic data based on ranges and patterns from the original data\n",
    "sizes = np.random.randint(1400, 3000, num_samples)  # Random sizes between 1400 and 3000 sq ft\n",
    "bedrooms = np.random.choice([2, 3, 4, 5, 6], num_samples)  # Random number of bedrooms between 2 and 6\n",
    "\n",
    "# Generate prices based on a linear relationship with size and bedrooms, and add some noise\n",
    "base_price = 200000 + sizes * 100 + bedrooms * 50000\n",
    "prices = base_price + np.random.normal(0, 25000, num_samples)  # Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31962da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "data = {\n",
    "    'Size (sq ft)': sizes,\n",
    "    'Bedrooms': bedrooms,\n",
    "    'Price ($)': prices.astype(int)  # Convert to integer\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the generated data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b874f710",
   "metadata": {},
   "source": [
    "### Step 3: Separate features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59abcf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Size (sq ft)', 'Bedrooms']]\n",
    "y = df['Price ($)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308cffa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be7825",
   "metadata": {},
   "source": [
    "### Step 4: Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c02557",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X: Features (independent variables) in the dataset\n",
    "# y: Target (dependent variable) in the dataset\n",
    "\n",
    "# test_size=0.2: Specifies that 20% of the data should be used for the test set, \n",
    "# and the remaining 80% for the training set.\n",
    "\n",
    "# random_state=42: Ensures that the data is split in the same way every time you run the code, \n",
    "# providing reproducibility. The number 42 is arbitrary and can be any integer.\n",
    "\n",
    "# X_train: Training data for the features\n",
    "# X_test: Testing data for the features\n",
    "\n",
    "# y_train: Training data for the target\n",
    "# y_test: Testing data for the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5fb7fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335b206",
   "metadata": {},
   "source": [
    "### Step 5: Choose and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc745df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()  # Initialize a Linear Regression model\n",
    "model.fit(X_train, y_train)  # Train the model using the training data (X_train) and the corresponding target values (y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05f0359",
   "metadata": {},
   "source": [
    "#### Linear Regression Algorithm\n",
    "Model Formula:\n",
    "\n",
    "- `ð¦ = ð0 + ð1ð¥1 + ð2ð¥2`\n",
    "\n",
    "where:\n",
    "- `ð0`  is the intercept\n",
    "- `ð1` is the coefficient for house size\n",
    "- `Î¸2` is the coefficient for number of bedrooms \n",
    "- `ð¥1` is house size \n",
    "- `ð¥2`  is number of bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c872e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get out the coefficients and intercept\n",
    "print(f\"Intercept: {model.intercept_}\")\n",
    "print(f\"Coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5222e33",
   "metadata": {},
   "source": [
    "##### The linear regression equation based on these results would be:\n",
    "\n",
    "`ð¦ = 195203.3704513209 + 100.32761232 * (HouseÂ SizeÂ (sqÂ ft)) + 51483.21560206 * (Bedrooms)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a820f",
   "metadata": {},
   "source": [
    "### Step 6: Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b17e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the formula with the actual coefficients and intercept to make a prediction using a record in the test data\n",
    "y = 195203.3704513209 + 100.32761232 * 1606 + 51483.21560206 * 5\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3c1da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test) # Use the trained model to make predictions on the test data (X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe1c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc23e9e",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20827d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)  # Calculate the Mean Squared Error (MSE) between the actual values (y_test) and the predicted values (y_pred)\n",
    "rmse = np.sqrt(mse)  # Calculate the Root Mean Squared Error (RMSE) by taking the square root of the MSE, which provides the error in the same units as the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522f366d",
   "metadata": {},
   "source": [
    "- In essence, you find the **errors** (subtract each predicted value from the actual value) **E**\n",
    "- **Square** these errors___________________________________________________**S**\n",
    "- find the **mean** (average) of all of them ____________________________________ **M**\n",
    "- and take the square**root**  ________________________________________________**R**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25153674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Predictions:\", y_pred)\n",
    "# print(\"Actual values:\", y_test.values)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7341b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R-squared value\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the R-squared value\n",
    "print(f\"R-squared: {r2:.2f}\") # \".2f\" output in 2 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca4ee7",
   "metadata": {},
   "source": [
    "### What do these metrics mean??\n",
    "\n",
    "\n",
    "- **RMSE (Root Mean Squared Error)** tries to answer the question: \"How large, on average, are the errors in my model's predictions?\"\n",
    "    - **Optimal Value**: As close to 0 as possible.\n",
    "    - Lower RMSE indicates that the predictions are closer to the actual values, meaning smaller errors.\n",
    "    - Note that for values ranging over 500k, 20k is an acceptable RMSE value. This won't be the case for values below 100k for instance. A good RMSE in this case could  be around 2k or less.\n",
    "\n",
    "- **R-squared (`RÂ²`)** tries to answer the question: \"How well do my model's predictions explain the variability (\"distance\" from the mean) in the actual data?\" \n",
    "    - In essence how good is my model in making predictions\n",
    "    - **Optimal Value**: As close to 1 as possible.\n",
    "    - RÂ² = 1 means the model predicted everything perfectly.\n",
    "     - RÂ² = 0.5 means the predictions were no better than just using the average price of all the houses in the case.\n",
    "     - RÂ² less than 0.5 means the predictions were worse than just using the average every time.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22478d",
   "metadata": {},
   "source": [
    "### Predict the price of a new house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e5b38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_house = [[2500, 4]]  # Size: 2500 sq ft, 4 bedrooms\n",
    "predicted_price = model.predict(new_house)\n",
    "print(f\"Predicted price for the new house: ${predicted_price[0]:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d3c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the formula with the known coeficients and intercept\n",
    "\n",
    "predicted_price2 = 195203.3704513209 + 100.32761232 * 2500 + 51483.21560206 * 4\n",
    "print(f\"Predicted price for the new house: ${predicted_price2:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037dbabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice Question:\n",
    "# Train a model to predict house prices using only the House Size feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c891c",
   "metadata": {},
   "source": [
    "## Predict whether a house is \"Expensive\" or \"Affordable\" (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2cb3f0",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LogisticRegression model from scikit-learn's linear_model module\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import metrics for evaluating classification models from scikit-learn's metrics module\n",
    "from sklearn.metrics import accuracy_score  # To calculate the accuracy of the model\n",
    "from sklearn.metrics import confusion_matrix  # To create a confusion matrix for the model's predictions\n",
    "from sklearn.metrics import classification_report  # To generate a detailed classification report including precision, recall, F1-score, and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82155ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 100\n",
    "\n",
    "# Generate synthetic data based on the given ranges and patterns\n",
    "sizes = np.random.randint(1400, 3000, num_samples)  # Random sizes between 1400 and 3000 sq ft\n",
    "bedrooms = np.random.choice([2, 3, 4, 5, 6], num_samples)  # Random number of bedrooms between 2 and 6\n",
    "\n",
    "# Generate price categories based on a simple rule:\n",
    "# - 'Affordable' if size is less than 1900 sq ft and bedrooms are less than 5\n",
    "# - 'Expensive' otherwise\n",
    "price_category = np.where((sizes < 1900) & (bedrooms < 5), 'Affordable', 'Expensive')\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {\n",
    "    'Size (sq ft)': sizes,\n",
    "    'Bedrooms': bedrooms,\n",
    "    'Price Category': price_category\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the generated data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc972c0",
   "metadata": {},
   "source": [
    "### Step 3: Encode the target variable (convert categories to numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fd142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price Category'] = df['Price Category'].map({'Affordable': 0, 'Expensive': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c7ba7",
   "metadata": {},
   "source": [
    "### Step 4: Separate features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Size (sq ft)', 'Bedrooms']]\n",
    "y = df['Price Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af0f24",
   "metadata": {},
   "source": [
    "### Step 5: Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccec4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f87db64",
   "metadata": {},
   "source": [
    "### Step 6: Choose and train the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c304398",
   "metadata": {},
   "source": [
    "### What happens in the \"backend\"?\n",
    "\n",
    "In Logistic Regression, the process is a bit different from Linear Regression because instead of predicting a continuous outcome (like price), you're predicting a **probability that an instance belongs to a particular class** (like \"spam\" or \"not spam\" or in our case, \"expensive\" or \"affordable\").\n",
    "\n",
    "The steps involve \n",
    "\n",
    "- calculating the linear combination of the features like in linear regression, \n",
    "- applying a formula or function called the sigmoid function, \n",
    "- and then using a threshold (usually 0.5) to make a prediction. More like, is the result of the sigmoid function greater than or less than the set threshold (usually 0.5)\n",
    "\n",
    "**Steps to Make a Prediction with Logistic Regression**\n",
    "\n",
    "1. **Linear Combination**: Compute the linear combination of the features using the coefficients and intercept.\n",
    "\n",
    "   $\n",
    "   z = \\text{intercept} + \\text{coef}_1 \\times \\text{feature}_1 + \\text{coef}_2 \\times \\text{feature}_2 + \\dots\n",
    "   $ \n",
    "\n",
    "    or\n",
    "\n",
    "    `z = ð0 + ð1ð¥1 + ð2ð¥2 + ...`\n",
    "    \n",
    "2. **Apply Sigmoid Function**: Use the sigmoid function to convert the linear combination $(z)$ into a probability.  \n",
    "\n",
    "   $\n",
    "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "   $\n",
    "\n",
    "\n",
    "3. **Thresholding**: If the resulting probability is greater than or equal to 0.5, predict the class as 1 (e.g., \"expensive\"), otherwise, predict 0 (e.g., \"affordable\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb097bc",
   "metadata": {},
   "source": [
    "### Step 7: Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405e726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6536839",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred\n",
    "\n",
    "# Note that 1 means Expensive and 0 means Affordable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780fdc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients for each feature\n",
    "coefficients = model.coef_\n",
    "print(\"Coefficients:\", coefficients)\n",
    "\n",
    "# Get the intercept\n",
    "intercept = model.intercept_\n",
    "print(\"Intercept:\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb40211",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab754c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the formula with the gotten coefficients and intercept to make a prediction using a record in the test data\n",
    "\n",
    "#### Step 1: Calculate the Linear Combination (z)\n",
    "\n",
    "# Given coefficients and intercept\n",
    "intercept = -20.53181245\n",
    "coef_house_size = 0.00887793\n",
    "coef_bedrooms = 1.48555931\n",
    "\n",
    "# Input features from the record\n",
    "house_size = 2529\n",
    "bedrooms = 4\n",
    "\n",
    "# Calculate the linear combination (z)\n",
    "z = intercept + (coef_house_size * house_size) + (coef_bedrooms * bedrooms)\n",
    "print(\"z: \", z)\n",
    "\n",
    "#### Step 2: Apply the Sigmoid Function to Get the Probability\n",
    "\n",
    "probability = 1 / (1 + np.exp(-z))\n",
    "print(\"probability: \", probability)\n",
    "\n",
    "#### Step 3: Make a Prediction Based on the Probability\n",
    "\n",
    "# Predict class based on a threshold of 0.5\n",
    "prediction = 1 if probability >= 0.5 else 0\n",
    "print(\"prediction: \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with y_pred\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b91e3",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104339ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# 'accuracy_score' compares the predicted labels 'y_pred' with the true labels 'y_test' and calculates the proportion of correctly classified instances.\n",
    "\n",
    "# Generate the confusion matrix for the model's predictions\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# 'confusion_matrix' provides a matrix showing the number of true positives, false positives, true negatives, and false negatives.\n",
    "\n",
    "# Create a detailed classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "# 'classification_report' generates a report including metrics like precision, recall, F1-score, and support for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ec468",
   "metadata": {},
   "source": [
    "### Step 9: Output the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a3f70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Predictions:\", y_pred)\n",
    "print(\"Actual values:\", y_test.values)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fef51",
   "metadata": {},
   "source": [
    "### Predict the category of a new house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fa3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_house = [[2500, 4]]  # Size: 2500 sq ft, 4 bedrooms\n",
    "predicted_category = model.predict(new_house)\n",
    "category = \"Expensive\" if predicted_category[0] == 1 else \"Affordable\"\n",
    "print(f\"The new house is predicted to be: {category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec503e",
   "metadata": {},
   "source": [
    "**Confusion Matrix??**\n",
    "- **TP (4)**: Correctly predicted positives. \n",
    "- **FP (0)**: Incorrectly predicted positives.\n",
    "- **FN (0)**: Missed Positives (predicted as negative).\n",
    "- **TN (16)**: Correctly predicted negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724c1e0",
   "metadata": {},
   "source": [
    "### What do these metrics mean?\n",
    "\n",
    "- **Accuracy** tries to answer the question: \"What proportion of my model's predictions were correct?\"\n",
    "    - **Optimal Value**: As close to 100% or 1.0 as possible.\n",
    "    - For instance, if your accuracy is `0.85`, it means the model correctly predicted the outcome 85% of the time.\n",
    "    - **Note** that in **imbalanced datasets**, a high accuracy might be **misleading**, so precision, recall, or F1 score might be more appropriate.\n",
    "    - For instance, a model predicts all the records passed through it as boys and gets an accuracy of 0.9 Meanwhile out of the 100 records, 10 are actually girls and the rest boys. It got just 10 wrong but those 10 were all the girls in the dataset.\n",
    "---\n",
    "- **Precision** tries to answer the question: \"Of the instances predicted as positive by my model, how many were actually positive? (Roughly, how many false positives are there?)\"\n",
    "    - **Optimal Value:** As close to 1.0 (or 100%) as possible.\n",
    "    - In our case, Precision is about being careful when you say something is affordable.\n",
    "    - For instance: If the model says 10 houses are affordable, and 8 of them are actually affordable, the precision is 8 out of 10 (which is 80%).\n",
    "---\n",
    "- **Recall** tries to answer the question: \"Of the actual positive instances in the data, how many did my model correctly identify as positive? (Roughly, how many false negatives are there?)\"\n",
    "    - **Optimal Value:** As close to 1.0 (or 100%) as possible.\n",
    "    - In our case, **Recall** is about being thorough in predicting all the affordable houses.\n",
    "    - For instance: If there are 10 affordable houses in the dataset, and the model correctly predicts 8 of them, the recall is 8 out of 10 (which is 80%).\n",
    "\n",
    "---\n",
    "- **F1 Score** tries to answer the question: \"What is the balance between precision and recall in my model's performance?\"\n",
    "    - **Optimal Value:** As close to 1.0 (or 100%) as possible.\n",
    "    - A higher F1 score indicates a good balance between precision and recall, meaning the model performs well in both avoiding false positives and false negatives.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice Question:\n",
    "# Train a model to predict house prices using only the House Size feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d45117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff09c8a3",
   "metadata": {},
   "source": [
    "---\n",
    "_**Your Dataness**_,  \n",
    "`Obinna Oliseneku` (_**Hybraid**_)  \n",
    "**[LinkedIn](https://www.linkedin.com/in/obinnao/)** | **[GitHub](https://github.com/hybraid6)**  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
